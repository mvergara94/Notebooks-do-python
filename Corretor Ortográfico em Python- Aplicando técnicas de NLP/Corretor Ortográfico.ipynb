{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorando um projeto de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando um corpus textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "arquivo = io.open(\"dados/artigos.txt\", \"r\", encoding = \"utf-8\")\n",
    "artigos = arquivo.read()\n",
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_exemplo = 'Iká, tudo bem ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = texto_exemplo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iká,', 'tudo', 'bem', '?']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando NLTK para tokenizar um texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refinando a tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iká', ',', 'tudo', 'bem', '?']\n"
     ]
    }
   ],
   "source": [
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando palavras de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iká', 'tudo', 'bem']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contando palavras do Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numero de palavras no nosso artigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O numero de palavras do nosso artigo é : 403106\n"
     ]
    }
   ],
   "source": [
    "print(f'O numero de palavras do nosso artigo é : {len(lista_palavras)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'Temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "print(lista_palavras[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())    \n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_normalizada = normalizacao(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem', 'temos', 'a', 'seguinte', 'classe']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_normalizada[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lista_normalizada))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desenvolvendo e testando o corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lado esquerdo + letra + Direito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fatiando Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('l', 'gica')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = 'lgica'\n",
    "(lista[:1],lista[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operacao de insercao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "palavra_exemplo = 'lgica'\n",
    "\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo a função corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6368),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(lista_normalizada)\n",
    "frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada]/total_palavras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key = probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Incrementando o corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## operacao de delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavras_geradas = gerador_palavras(\"loigica\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aloigica', 'bloigica', 'cloigica', 'dloigica', 'eloigica', 'floigica', 'gloigica', 'hloigica', 'iloigica', 'jloigica', 'kloigica', 'lloigica', 'mloigica', 'nloigica', 'oloigica', 'ploigica', 'qloigica', 'rloigica', 'sloigica', 'tloigica', 'uloigica', 'vloigica', 'wloigica', 'xloigica', 'yloigica', 'zloigica', 'àloigica', 'áloigica', 'âloigica', 'ãloigica', 'èloigica', 'éloigica', 'êloigica', 'ìloigica', 'íloigica', 'îloigica', 'òloigica', 'óloigica', 'ôloigica', 'õloigica', 'ùloigica', 'úloigica', 'ûloigica', 'çloigica', 'laoigica', 'lboigica', 'lcoigica', 'ldoigica', 'leoigica', 'lfoigica', 'lgoigica', 'lhoigica', 'lioigica', 'ljoigica', 'lkoigica', 'lloigica', 'lmoigica', 'lnoigica', 'looigica', 'lpoigica', 'lqoigica', 'lroigica', 'lsoigica', 'ltoigica', 'luoigica', 'lvoigica', 'lwoigica', 'lxoigica', 'lyoigica', 'lzoigica', 'làoigica', 'láoigica', 'lâoigica', 'lãoigica', 'lèoigica', 'léoigica', 'lêoigica', 'lìoigica', 'líoigica', 'lîoigica', 'lòoigica', 'lóoigica', 'lôoigica', 'lõoigica', 'lùoigica', 'lúoigica', 'lûoigica', 'lçoigica', 'loaigica', 'lobigica', 'locigica', 'lodigica', 'loeigica', 'lofigica', 'logigica', 'lohigica', 'loiigica', 'lojigica', 'lokigica', 'loligica', 'lomigica', 'lonigica', 'looigica', 'lopigica', 'loqigica', 'lorigica', 'losigica', 'lotigica', 'louigica', 'lovigica', 'lowigica', 'loxigica', 'loyigica', 'lozigica', 'loàigica', 'loáigica', 'loâigica', 'loãigica', 'loèigica', 'loéigica', 'loêigica', 'loìigica', 'loíigica', 'loîigica', 'loòigica', 'loóigica', 'loôigica', 'loõigica', 'loùigica', 'loúigica', 'loûigica', 'loçigica', 'loiagica', 'loibgica', 'loicgica', 'loidgica', 'loiegica', 'loifgica', 'loiggica', 'loihgica', 'loiigica', 'loijgica', 'loikgica', 'loilgica', 'loimgica', 'loingica', 'loiogica', 'loipgica', 'loiqgica', 'loirgica', 'loisgica', 'loitgica', 'loiugica', 'loivgica', 'loiwgica', 'loixgica', 'loiygica', 'loizgica', 'loiàgica', 'loiágica', 'loiâgica', 'loiãgica', 'loiègica', 'loiégica', 'loiêgica', 'loiìgica', 'loiígica', 'loiîgica', 'loiògica', 'loiógica', 'loiôgica', 'loiõgica', 'loiùgica', 'loiúgica', 'loiûgica', 'loiçgica', 'loigaica', 'loigbica', 'loigcica', 'loigdica', 'loigeica', 'loigfica', 'loiggica', 'loighica', 'loigiica', 'loigjica', 'loigkica', 'loiglica', 'loigmica', 'loignica', 'loigoica', 'loigpica', 'loigqica', 'loigrica', 'loigsica', 'loigtica', 'loiguica', 'loigvica', 'loigwica', 'loigxica', 'loigyica', 'loigzica', 'loigàica', 'loigáica', 'loigâica', 'loigãica', 'loigèica', 'loigéica', 'loigêica', 'loigìica', 'loigíica', 'loigîica', 'loigòica', 'loigóica', 'loigôica', 'loigõica', 'loigùica', 'loigúica', 'loigûica', 'loigçica', 'loigiaca', 'loigibca', 'loigicca', 'loigidca', 'loigieca', 'loigifca', 'loigigca', 'loigihca', 'loigiica', 'loigijca', 'loigikca', 'loigilca', 'loigimca', 'loiginca', 'loigioca', 'loigipca', 'loigiqca', 'loigirca', 'loigisca', 'loigitca', 'loigiuca', 'loigivca', 'loigiwca', 'loigixca', 'loigiyca', 'loigizca', 'loigiàca', 'loigiáca', 'loigiâca', 'loigiãca', 'loigièca', 'loigiéca', 'loigiêca', 'loigiìca', 'loigiíca', 'loigiîca', 'loigiòca', 'loigióca', 'loigiôca', 'loigiõca', 'loigiùca', 'loigiúca', 'loigiûca', 'loigiçca', 'loigicaa', 'loigicba', 'loigicca', 'loigicda', 'loigicea', 'loigicfa', 'loigicga', 'loigicha', 'loigicia', 'loigicja', 'loigicka', 'loigicla', 'loigicma', 'loigicna', 'loigicoa', 'loigicpa', 'loigicqa', 'loigicra', 'loigicsa', 'loigicta', 'loigicua', 'loigicva', 'loigicwa', 'loigicxa', 'loigicya', 'loigicza', 'loigicàa', 'loigicáa', 'loigicâa', 'loigicãa', 'loigicèa', 'loigicéa', 'loigicêa', 'loigicìa', 'loigicía', 'loigicîa', 'loigicòa', 'loigicóa', 'loigicôa', 'loigicõa', 'loigicùa', 'loigicúa', 'loigicûa', 'loigicça', 'loigicaa', 'loigicab', 'loigicac', 'loigicad', 'loigicae', 'loigicaf', 'loigicag', 'loigicah', 'loigicai', 'loigicaj', 'loigicak', 'loigical', 'loigicam', 'loigican', 'loigicao', 'loigicap', 'loigicaq', 'loigicar', 'loigicas', 'loigicat', 'loigicau', 'loigicav', 'loigicaw', 'loigicax', 'loigicay', 'loigicaz', 'loigicaà', 'loigicaá', 'loigicaâ', 'loigicaã', 'loigicaè', 'loigicaé', 'loigicaê', 'loigicaì', 'loigicaí', 'loigicaî', 'loigicaò', 'loigicaó', 'loigicaô', 'loigicaõ', 'loigicaù', 'loigicaú', 'loigicaû', 'loigicaç', 'oigica', 'ligica', 'logica', 'loiica', 'loigca', 'loigia', 'loigic', 'loigica']\n"
     ]
    }
   ],
   "source": [
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrigindo os principais erros de digitação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando a troca de letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def troca_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_letras(fatias)\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgàica', 'lgáica', 'lgâica', 'lgãica', 'lgèica', 'lgéica', 'lgêica', 'lgìica', 'lgíica', 'lgîica', 'lgòica', 'lgóica', 'lgôica', 'lgõica', 'lgùica', 'lgúica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiàca', 'lgiáca', 'lgiâca', 'lgiãca', 'lgièca', 'lgiéca', 'lgiêca', 'lgiìca', 'lgiíca', 'lgiîca', 'lgiòca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiùca', 'lgiúca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicàa', 'lgicáa', 'lgicâa', 'lgicãa', 'lgicèa', 'lgicéa', 'lgicêa', 'lgicìa', 'lgicía', 'lgicîa', 'lgicòa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicùa', 'lgicúa', 'lgicûa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç', 'gica', 'lica', 'lgca', 'lgia', 'lgic', 'lgica', 'agica', 'bgica', 'cgica', 'dgica', 'egica', 'fgica', 'ggica', 'hgica', 'igica', 'jgica', 'kgica', 'lgica', 'mgica', 'ngica', 'ogica', 'pgica', 'qgica', 'rgica', 'sgica', 'tgica', 'ugica', 'vgica', 'wgica', 'xgica', 'ygica', 'zgica', 'àgica', 'ágica', 'âgica', 'ãgica', 'ègica', 'égica', 'êgica', 'ìgica', 'ígica', 'îgica', 'ògica', 'ógica', 'ôgica', 'õgica', 'ùgica', 'úgica', 'ûgica', 'çgica', 'laica', 'lbica', 'lcica', 'ldica', 'leica', 'lfica', 'lgica', 'lhica', 'liica', 'ljica', 'lkica', 'llica', 'lmica', 'lnica', 'loica', 'lpica', 'lqica', 'lrica', 'lsica', 'ltica', 'luica', 'lvica', 'lwica', 'lxica', 'lyica', 'lzica', 'làica', 'láica', 'lâica', 'lãica', 'lèica', 'léica', 'lêica', 'lìica', 'líica', 'lîica', 'lòica', 'lóica', 'lôica', 'lõica', 'lùica', 'lúica', 'lûica', 'lçica', 'lgaca', 'lgbca', 'lgcca', 'lgdca', 'lgeca', 'lgfca', 'lggca', 'lghca', 'lgica', 'lgjca', 'lgkca', 'lglca', 'lgmca', 'lgnca', 'lgoca', 'lgpca', 'lgqca', 'lgrca', 'lgsca', 'lgtca', 'lguca', 'lgvca', 'lgwca', 'lgxca', 'lgyca', 'lgzca', 'lgàca', 'lgáca', 'lgâca', 'lgãca', 'lgèca', 'lgéca', 'lgêca', 'lgìca', 'lgíca', 'lgîca', 'lgòca', 'lgóca', 'lgôca', 'lgõca', 'lgùca', 'lgúca', 'lgûca', 'lgçca', 'lgiaa', 'lgiba', 'lgica', 'lgida', 'lgiea', 'lgifa', 'lgiga', 'lgiha', 'lgiia', 'lgija', 'lgika', 'lgila', 'lgima', 'lgina', 'lgioa', 'lgipa', 'lgiqa', 'lgira', 'lgisa', 'lgita', 'lgiua', 'lgiva', 'lgiwa', 'lgixa', 'lgiya', 'lgiza', 'lgiàa', 'lgiáa', 'lgiâa', 'lgiãa', 'lgièa', 'lgiéa', 'lgiêa', 'lgiìa', 'lgiía', 'lgiîa', 'lgiòa', 'lgióa', 'lgiôa', 'lgiõa', 'lgiùa', 'lgiúa', 'lgiûa', 'lgiça', 'lgica', 'lgicb', 'lgicc', 'lgicd', 'lgice', 'lgicf', 'lgicg', 'lgich', 'lgici', 'lgicj', 'lgick', 'lgicl', 'lgicm', 'lgicn', 'lgico', 'lgicp', 'lgicq', 'lgicr', 'lgics', 'lgict', 'lgicu', 'lgicv', 'lgicw', 'lgicx', 'lgicy', 'lgicz', 'lgicà', 'lgicá', 'lgicâ', 'lgicã', 'lgicè', 'lgicé', 'lgicê', 'lgicì', 'lgicí', 'lgicî', 'lgicò', 'lgicó', 'lgicô', 'lgicõ', 'lgicù', 'lgicú', 'lgicû', 'lgicç', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç']\n"
     ]
    }
   ],
   "source": [
    "palavras_exemplo = 'lígica'\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupando as operações do corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aula', 'bula', 'cula', 'dula', 'eula', 'fula', 'gula', 'hula', 'iula', 'jula', 'kula', 'lula', 'mula', 'nula', 'oula', 'pula', 'qula', 'rula', 'sula', 'tula', 'uula', 'vula', 'wula', 'xula', 'yula', 'zula', 'àula', 'áula', 'âula', 'ãula', 'èula', 'éula', 'êula', 'ìula', 'íula', 'îula', 'òula', 'óula', 'ôula', 'õula', 'ùula', 'úula', 'ûula', 'çula', 'uala', 'ubla', 'ucla', 'udla', 'uela', 'ufla', 'ugla', 'uhla', 'uila', 'ujla', 'ukla', 'ulla', 'umla', 'unla', 'uola', 'upla', 'uqla', 'urla', 'usla', 'utla', 'uula', 'uvla', 'uwla', 'uxla', 'uyla', 'uzla', 'uàla', 'uála', 'uâla', 'uãla', 'uèla', 'uéla', 'uêla', 'uìla', 'uíla', 'uîla', 'uòla', 'uóla', 'uôla', 'uõla', 'uùla', 'uúla', 'uûla', 'uçla', 'ulaa', 'ulba', 'ulca', 'ulda', 'ulea', 'ulfa', 'ulga', 'ulha', 'ulia', 'ulja', 'ulka', 'ulla', 'ulma', 'ulna', 'uloa', 'ulpa', 'ulqa', 'ulra', 'ulsa', 'ulta', 'ulua', 'ulva', 'ulwa', 'ulxa', 'ulya', 'ulza', 'ulàa', 'uláa', 'ulâa', 'ulãa', 'ulèa', 'uléa', 'ulêa', 'ulìa', 'ulía', 'ulîa', 'ulòa', 'ulóa', 'ulôa', 'ulõa', 'ulùa', 'ulúa', 'ulûa', 'ulça', 'ulaa', 'ulab', 'ulac', 'ulad', 'ulae', 'ulaf', 'ulag', 'ulah', 'ulai', 'ulaj', 'ulak', 'ulal', 'ulam', 'ulan', 'ulao', 'ulap', 'ulaq', 'ular', 'ulas', 'ulat', 'ulau', 'ulav', 'ulaw', 'ulax', 'ulay', 'ulaz', 'ulaà', 'ulaá', 'ulaâ', 'ulaã', 'ulaè', 'ulaé', 'ulaê', 'ulaì', 'ulaí', 'ulaî', 'ulaò', 'ulaó', 'ulaô', 'ulaõ', 'ulaù', 'ulaú', 'ulaû', 'ulaç', 'la', 'ua', 'ul', 'ula', 'ala', 'bla', 'cla', 'dla', 'ela', 'fla', 'gla', 'hla', 'ila', 'jla', 'kla', 'lla', 'mla', 'nla', 'ola', 'pla', 'qla', 'rla', 'sla', 'tla', 'ula', 'vla', 'wla', 'xla', 'yla', 'zla', 'àla', 'ála', 'âla', 'ãla', 'èla', 'éla', 'êla', 'ìla', 'íla', 'îla', 'òla', 'óla', 'ôla', 'õla', 'ùla', 'úla', 'ûla', 'çla', 'uaa', 'uba', 'uca', 'uda', 'uea', 'ufa', 'uga', 'uha', 'uia', 'uja', 'uka', 'ula', 'uma', 'una', 'uoa', 'upa', 'uqa', 'ura', 'usa', 'uta', 'uua', 'uva', 'uwa', 'uxa', 'uya', 'uza', 'uàa', 'uáa', 'uâa', 'uãa', 'uèa', 'uéa', 'uêa', 'uìa', 'uía', 'uîa', 'uòa', 'uóa', 'uôa', 'uõa', 'uùa', 'uúa', 'uûa', 'uça', 'ula', 'ulb', 'ulc', 'uld', 'ule', 'ulf', 'ulg', 'ulh', 'uli', 'ulj', 'ulk', 'ull', 'ulm', 'uln', 'ulo', 'ulp', 'ulq', 'ulr', 'uls', 'ult', 'ulu', 'ulv', 'ulw', 'ulx', 'uly', 'ulz', 'ulà', 'ulá', 'ulâ', 'ulã', 'ulè', 'ulé', 'ulê', 'ulì', 'ulí', 'ulî', 'ulò', 'uló', 'ulô', 'ulõ', 'ulù', 'ulú', 'ulû', 'ulç', 'ulaa', 'ulab', 'ulac', 'ulad', 'ulae', 'ulaf', 'ulag', 'ulah', 'ulai', 'ulaj', 'ulak', 'ulal', 'ulam', 'ulan', 'ulao', 'ulap', 'ulaq', 'ular', 'ulas', 'ulat', 'ulau', 'ulav', 'ulaw', 'ulax', 'ulay', 'ulaz', 'ulaà', 'ulaá', 'ulaâ', 'ulaã', 'ulaè', 'ulaé', 'ulaê', 'ulaì', 'ulaí', 'ulaî', 'ulaò', 'ulaó', 'ulaô', 'ulaõ', 'ulaù', 'ulaú', 'ulaû', 'ulaç', 'lua', 'ual']\n"
     ]
    }
   ],
   "source": [
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras\n",
    "\n",
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def troca_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])\n",
    "    return novas_palavras\n",
    "\n",
    "def inverte_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])\n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i],palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_letras(fatias)\n",
    "    palavras_geradas += inverte_letras(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavra_exemplo = 'ula'\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melhorando o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavra = 'lóiigica'\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "palavras_g = gerador_turbinado(gerador_palavras(palavra))\n",
    "'lógica' in palavras_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691744"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    palavra_correta = max(candidatos, key = probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novo_corretor('lóiigica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliando a qualidade do corretor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando dados teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo,'r', encoding = 'utf-8')\n",
    "    for linha in f:\n",
    "        correta, errada = linha.split()\n",
    "        lista_palavras_teste.append((correta,errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "\n",
    "lista_teste = cria_dados_teste(\"dados/palavras.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm'),\n",
       " ('ele', 'eme'),\n",
       " ('fazer', 'èazer'),\n",
       " ('temos', 'temfs'),\n",
       " ('essa', 'eàssa'),\n",
       " ('quando', 'quaôdo'),\n",
       " ('vamos', 'vamvos'),\n",
       " ('sobre', 'hsobre'),\n",
       " ('java', 'sjava'),\n",
       " ('das', 'daõs'),\n",
       " ('agora', 'agorah'),\n",
       " ('está', 'eòtá'),\n",
       " ('cada', 'céda'),\n",
       " ('mesmo', 'zmesmo'),\n",
       " ('nos', 'noâ'),\n",
       " ('forma', 'fobma'),\n",
       " ('seja', 'sejéa'),\n",
       " ('então', 'enêão'),\n",
       " ('criar', 'èriar'),\n",
       " ('código', 'cóeigo'),\n",
       " ('caso', 'casío'),\n",
       " ('exemplo', 'áexemplo'),\n",
       " ('tem', 'tĩem'),\n",
       " ('usuário', 'usuárôio'),\n",
       " ('dados', 'dfados'),\n",
       " ('python', 'pgthon'),\n",
       " ('nossa', 'nossah'),\n",
       " ('além', 'alémè'),\n",
       " ('assim', 'asõim'),\n",
       " ('ter', 'teb'),\n",
       " ('até', 'atĩ'),\n",
       " ('bem', 'âem'),\n",
       " ('design', 'desigen'),\n",
       " ('trabalho', 'trabalàho'),\n",
       " ('foi', 'foo'),\n",
       " ('apenas', 'apenaũ'),\n",
       " ('empresa', 'empresà'),\n",
       " ('valor', 'valíor'),\n",
       " ('será', 'serr'),\n",
       " ('entre', 'entke'),\n",
       " ('método', 'méqodo'),\n",
       " ('precisamos', 'precisamops'),\n",
       " ('ainda', 'ainàa'),\n",
       " ('vai', 'van'),\n",
       " ('conteúdo', 'ûconteúdo'),\n",
       " ('seus', 'çeus'),\n",
       " ('eu', 'eû'),\n",
       " ('todos', 'todtos'),\n",
       " ('tempo', 'temeo'),\n",
       " ('sempre', 'semre'),\n",
       " ('qual', 'quakl'),\n",
       " ('ela', 'elaá'),\n",
       " ('só', 'síó'),\n",
       " ('utilizar', 'utiqizar'),\n",
       " ('projeto', 'prhojeto'),\n",
       " ('site', 'siàe'),\n",
       " ('sem', 'seém'),\n",
       " ('pelo', 'peln'),\n",
       " ('alura', 'aléra'),\n",
       " ('dia', 'tdia'),\n",
       " ('tudo', 'tuúo'),\n",
       " ('podemos', 'kpodemos'),\n",
       " ('esse', 'eẽsse'),\n",
       " ('já', 'jé'),\n",
       " ('nosso', 'nçosso'),\n",
       " ('são', 'sãô'),\n",
       " ('dos', 'odos'),\n",
       " ('muito', 'tuito'),\n",
       " ('imagem', 'imõgem'),\n",
       " ('sua', 'siua'),\n",
       " ('também', 'tamvbém'),\n",
       " ('ele', 'elpe'),\n",
       " ('fazer', 'façzer'),\n",
       " ('temos', 'teos'),\n",
       " ('essa', 'eũsa'),\n",
       " ('quando', 'quaìdo'),\n",
       " ('vamos', 'vjmos'),\n",
       " ('sobre', 'sxobre'),\n",
       " ('java', 'jkva'),\n",
       " ('das', 'dms'),\n",
       " ('agora', 'agtora'),\n",
       " ('está', 'esútá'),\n",
       " ('cada', 'cava'),\n",
       " ('mesmo', 'medmo'),\n",
       " ('nos', 'ános'),\n",
       " ('forma', 'forûa'),\n",
       " ('seja', 'smeja'),\n",
       " ('então', 'enjtão'),\n",
       " ('criar', 'criôar'),\n",
       " ('código', 'cóàigo'),\n",
       " ('caso', 'èaso'),\n",
       " ('exemplo', 'exbemplo'),\n",
       " ('tem', 'túem'),\n",
       " ('usuário', 'usuárin'),\n",
       " ('dados', 'daáos'),\n",
       " ('python', 'pythoçn'),\n",
       " ('nossa', 'nossk'),\n",
       " ('além', 'âlém'),\n",
       " ('assim', 'aóssim'),\n",
       " ('ter', 'tãer'),\n",
       " ('até', 'vté'),\n",
       " ('bem', 'búm'),\n",
       " ('design', 'íesign'),\n",
       " ('trabalho', 'trabèalho'),\n",
       " ('foi', 'kfoi'),\n",
       " ('apenas', 'aapenas'),\n",
       " ('empresa', 'pmpresa'),\n",
       " ('valor', 'valoqr'),\n",
       " ('será', 'sçerá'),\n",
       " ('entre', 'entró'),\n",
       " ('método', 'nétodo'),\n",
       " ('precisamos', 'prefcisamos'),\n",
       " ('ainda', 'sainda'),\n",
       " ('vai', 'uai'),\n",
       " ('conteúdo', 'cĩonteúdo'),\n",
       " ('seus', 'sâus'),\n",
       " ('eu', 'ìeu'),\n",
       " ('todos', 'todás'),\n",
       " ('tempo', 'utempo'),\n",
       " ('sempre', 'sempce'),\n",
       " ('qual', 'fual'),\n",
       " ('ela', 'elal'),\n",
       " ('só', 'skó'),\n",
       " ('utilizar', 'utilĩzar'),\n",
       " ('projeto', 'proójeto'),\n",
       " ('site', 'isite'),\n",
       " ('sem', 'secm'),\n",
       " ('pelo', 'pẽlo'),\n",
       " ('alura', 'aluéa'),\n",
       " ('dia', 'dil'),\n",
       " ('tudo', 'tudy'),\n",
       " ('ela', 'qelay'),\n",
       " ('só', 'sód'),\n",
       " ('utilizar', 'dtilizacr'),\n",
       " ('projeto', 'bprojõto'),\n",
       " ('site', 'ysiteo'),\n",
       " ('sem', 'sõêm'),\n",
       " ('pelo', 'peàli'),\n",
       " ('alura', 'asuraó'),\n",
       " ('dia', 'deiìa'),\n",
       " ('tudo', 'tuĩdoì'),\n",
       " ('ela', 'eúaa'),\n",
       " ('só', 'ró'),\n",
       " ('utilizar', 'utilizẽaçr'),\n",
       " ('projeto', 'prêjetó'),\n",
       " ('site', 'sqiqte'),\n",
       " ('sem', 'sũexm'),\n",
       " ('pelo', 'pçlxo'),\n",
       " ('alura', 'uluraa'),\n",
       " ('dia', 'dĩaz'),\n",
       " ('tudo', 'kzudo'),\n",
       " ('corretor', 'correptor'),\n",
       " ('tática', 'trtica'),\n",
       " ('empoderamento', 'ewpoderamento'),\n",
       " ('linux', 'lifux'),\n",
       " ('cachorro', 'cachoçro'),\n",
       " ('gato', 'îgato'),\n",
       " ('cavalo', 'cakvalo'),\n",
       " ('relógio', 'relógiuo'),\n",
       " ('canela', 'canelac'),\n",
       " ('tênis', 'tênisy'),\n",
       " ('ansiosa', 'anciosa'),\n",
       " ('ansiosa', 'ancciosa'),\n",
       " ('ansiosa', 'ansioa'),\n",
       " ('empoderamento', 'empoderamento'),\n",
       " ('asterisco', 'asterístico'),\n",
       " ('gratuito', 'gratuíto'),\n",
       " ('entretido', 'entertido'),\n",
       " ('ritmo', 'ritimo'),\n",
       " ('idiota', 'indiota'),\n",
       " ('tomara', 'tomare'),\n",
       " ('seja', 'seje'),\n",
       " ('prevalecer', 'provalecer'),\n",
       " ('esteja', 'esteje'),\n",
       " ('mendigo', 'mindigo'),\n",
       " ('cérebro', 'célebro'),\n",
       " ('perturbar', 'pertubar')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta,errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round(acertou*100/numero_palavras,2)\n",
    "    taxa_desconhecida = round(desconhecida*100/numero_palavras,2)\n",
    "    print(f\"{taxa_acerto}% de {numero_palavras} palavras, desconhecidas eh {taxa_desconhecida}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34% de 186 palavras, desconhecidas eh 6.99%\n"
     ]
    }
   ],
   "source": [
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
